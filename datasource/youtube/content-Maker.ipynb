{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 â€” Setup\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ðŸ”§ Change this to your CSV path\n",
    "csv_path = Path(\"videos.csv\")  # e.g., \"my_youtube.csv\"\n",
    "json_path = Path(\"youtube-scrape.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7952e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 â€” Load CSV (treat everything as string to avoid ID corruption)\n",
    "# We'll still parse published_date separately if needed.\n",
    "\n",
    "# Read all columns as string so we don't lose leading zeros or IDs\n",
    "df = pd.read_csv(csv_path, dtype=str)\n",
    "\n",
    "# Normalize column names (strip spaces if any)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Make sure these columns exist (optional; remove/adjust if your CSV differs)\n",
    "expected_cols = [\n",
    "    \"source\",\"channel_name\",\"channel_id\",\"video_id\",\"title\",\"url\",\"description\",\n",
    "    \"published_date\",\"keyword\",\"trust_score\",\"query\",\"view_count\",\"like_count\",\n",
    "    \"duration\",\"educational_score\"\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Warning: Missing columns in CSV:\", missing)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 â€” Clean & convert NaNs to None, and coerce numeric fields if present\n",
    "\n",
    "def coerce_numeric(val):\n",
    "    if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if s == \"\" or s.lower() == \"nan\":\n",
    "        return None\n",
    "    try:\n",
    "        # prefer int if it looks like an integer, else float\n",
    "        if s.isdigit():\n",
    "            return int(s)\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return s  # leave as string if not numeric\n",
    "\n",
    "def clean_row(row: dict) -> dict:\n",
    "    out = {}\n",
    "    for k, v in row.items():\n",
    "        # Convert NaN/empty to None\n",
    "        if v is None:\n",
    "            out[k] = None\n",
    "            continue\n",
    "        s = str(v).strip()\n",
    "        if s == \"\" or s.lower() == \"nan\":\n",
    "            out[k] = None\n",
    "            continue\n",
    "        out[k] = s\n",
    "\n",
    "    # Optional: coerce known numeric fields\n",
    "    for num_col in [\"trust_score\", \"view_count\", \"like_count\", \"duration\", \"educational_score\"]:\n",
    "        if num_col in out:\n",
    "            out[num_col] = coerce_numeric(out[num_col])\n",
    "\n",
    "    return out\n",
    "\n",
    "records = [clean_row(r) for r in df.to_dict(orient=\"records\")]\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 â€” Append to youtube-scrape.json (create if not exists)\n",
    "# This writes an array of JSON objects. If the file exists, it loads, appends, de-duplicates by video_id, and saves.\n",
    "\n",
    "existing = []\n",
    "if json_path.exists():\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                existing = data\n",
    "            else:\n",
    "                print(\"Warning: Existing JSON is not a list. Starting fresh array.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Existing JSON invalid. Starting fresh array.\")\n",
    "\n",
    "# Merge\n",
    "combined = existing + records\n",
    "\n",
    "# De-duplicate by `video_id` if present\n",
    "def dedup_by_key(items, key=\"video_id\"):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for it in items:\n",
    "        vid = (it or {}).get(key)\n",
    "        if vid is not None:\n",
    "            if vid in seen:\n",
    "                continue\n",
    "            seen.add(vid)\n",
    "        out.append(it)\n",
    "    return out\n",
    "\n",
    "combined = dedup_by_key(combined, key=\"video_id\")\n",
    "\n",
    "# Save\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Wrote {len(combined)} total records to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5982a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 â€” Quick peek\n",
    "# Show the last few appended entries (optional)\n",
    "pd.DataFrame(records).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62233ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import youtube-scrape.json file and travers each item in json\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Load the JSON file\n",
    "with open('youtube-scrape.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f) # data is a list of dictionaries\n",
    "print(f\"Total videos in JSON: {len(data)}\")\n",
    "# Create a directory to store transcripts if it doesn't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8838a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping video_id 2njn71TqkjA as content already exists\n",
      "Skipping video_id ZCKRjP_DMII as content already exists\n",
      "Skipping video_id JYZpxRy5Mfg as content already exists\n",
      "Skipping video_id 3hxE7Af98AI as content already exists\n",
      "Skipping video_id _vDZmVXtA7k as content already exists\n",
      "Skipping video_id sDo7saKaEys as content already exists\n",
      "Skipping video_id ImmFkjFm-k0 as content already exists\n",
      "Skipping video_id M3XZBYVSnJ0 as content already exists\n",
      "Skipping video_id 128fp0rqfbE as content already exists\n",
      "Skipping video_id bbxmH_Kj7fk as content already exists\n",
      "Skipping video_id -EJOO3xAjTk as content already exists\n",
      "Skipping video_id 2fyX600dL2g as content already exists\n",
      "Skipping video_id RnvCbquYeIM as content already exists\n",
      "Fetched transcript for video_id xKxrkht7CpY\n",
      "Fetched transcript for video_id DW0jTe80kmM\n",
      "Fetched transcript for video_id WcLlpWmEpQ8\n",
      "Fetched transcript for video_id dhiWSsKUWEg\n",
      "Fetched transcript for video_id xy9nj94xvKA\n",
      "Fetched transcript for video_id fHztd6k5ZXY\n",
      "Fetched transcript for video_id tjwrG4Debc4\n",
      "Fetched transcript for video_id 5Hb_ONJUA9I\n",
      "Fetched transcript for video_id EtW2rrLHs08\n",
      "Fetched transcript for video_id WJgpDyP9ewQ\n",
      "Fetched transcript for video_id MEFkBeYhJdw\n",
      "Fetched transcript for video_id B-nEYsyRlYo\n",
      "Fetched transcript for video_id -5KEgq1f7J0\n",
      "Fetched transcript for video_id 07PYCbcMgio\n",
      "Fetched transcript for video_id FmbU36f4ios\n",
      "Fetched transcript for video_id zqJ7LQ8KGMc\n",
      "Fetched transcript for video_id 3n63cqnhzVk\n",
      "Fetched transcript for video_id l0bKxgyEvTc\n",
      "Fetched transcript for video_id ZIpyxJY2Cd8\n",
      "Fetched transcript for video_id pB_I6XR4c6I\n",
      "Fetched transcript for video_id YQba3ENhlKA\n",
      "Fetched transcript for video_id CH2BEW22oj4\n",
      "Fetched transcript for video_id scl__1pQ5bc\n",
      "Fetched transcript for video_id ZKOavgDCQYo\n",
      "Fetched transcript for video_id EUXgz6RsEUo\n",
      "Fetched transcript for video_id Qmxxsf_AJ3w\n",
      "Fetched transcript for video_id ZsJUs_mfQMY\n",
      "Fetched transcript for video_id IwdtXGAtgvE\n",
      "Error fetching transcript for video_id raUyrYRiqt4: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=raUyrYRiqt4! This is most likely caused by:\n",
      "\n",
      "Subtitles are disabled for this video\n",
      "\n",
      "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n",
      "Fetched transcript for video_id dIsjcG7hTmo\n",
      "Fetched transcript for video_id febBRv2Vftk\n",
      "Fetched transcript for video_id B5Fwl4P4EW8\n",
      "Fetched transcript for video_id NB6_5lbpl3A\n",
      "Fetched transcript for video_id i730XRQm0A8\n",
      "Fetched transcript for video_id NyLt-m_UqUM\n",
      "Fetched transcript for video_id un2_TgSWq1c\n",
      "Fetched transcript for video_id rFdkrgj0NG0\n",
      "Fetched transcript for video_id 1_HBgvmrhGU\n",
      "Fetched transcript for video_id cyAKX_jYnvI\n",
      "Fetched transcript for video_id c0TJsFpvj_A\n",
      "Fetched transcript for video_id 93nk2xIRcbk\n",
      "Fetched transcript for video_id tMwFNMfjFuU\n",
      "Fetched transcript for video_id Y1mPWVzaGQY\n",
      "Fetched transcript for video_id 9PFhrpyWV-w\n",
      "Fetched transcript for video_id ML70W4O6F4E\n",
      "Error fetching transcript for video_id HsAUGbUgx6Y: \n",
      "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=HsAUGbUgx6Y! This is most likely caused by:\n",
      "\n",
      "No transcripts were found for any of the requested language codes: ('en',)\n",
      "\n",
      "For this video (HsAUGbUgx6Y) transcripts are available in the following languages:\n",
      "\n",
      "(MANUALLY CREATED)\n",
      " - en-US (\"English (United States)\")[TRANSLATABLE]\n",
      "\n",
      "(GENERATED)\n",
      "None\n",
      "\n",
      "(TRANSLATION LANGUAGES)\n",
      " - ar (\"Arabic\")\n",
      " - zh-Hant (\"Chinese (Traditional)\")\n",
      " - nl (\"Dutch\")\n",
      " - fr (\"French\")\n",
      " - de (\"German\")\n",
      " - hi (\"Hindi\")\n",
      " - id (\"Indonesian\")\n",
      " - it (\"Italian\")\n",
      " - ja (\"Japanese\")\n",
      " - ko (\"Korean\")\n",
      " - pt (\"Portuguese\")\n",
      " - ru (\"Russian\")\n",
      " - es (\"Spanish\")\n",
      " - th (\"Thai\")\n",
      " - tr (\"Turkish\")\n",
      " - uk (\"Ukrainian\")\n",
      " - vi (\"Vietnamese\")\n",
      "\n",
      "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n",
      "Fetched transcript for video_id 3p51wKUuwOU\n",
      "Fetched transcript for video_id 5eTCZ9L834s\n",
      "Fetched transcript for video_id eVUuwHGLIYo\n",
      "Fetched transcript for video_id YF8AAJSTJoM\n",
      "Fetched transcript for video_id g3vf0I_j9kk\n",
      "Fetched transcript for video_id pT7vRUGeEtA\n",
      "Fetched transcript for video_id dhFlDkES6Ws\n",
      "Fetched transcript for video_id Z5YvjG4lTpQ\n",
      "Fetched transcript for video_id 4k5gyYAAEEU\n",
      "Fetched transcript for video_id v6uRuNboy4A\n",
      "Fetched transcript for video_id rDkaZWirNME\n",
      "Fetched transcript for video_id EM1IyIyr-Zc\n",
      "Fetched transcript for video_id ivWXuOd5SrI\n",
      "Fetched transcript for video_id 7ODrQW0vSmA\n",
      "Fetched transcript for video_id Q26Z4JWVZvk\n",
      "Fetched transcript for video_id 1-YtC3nwWwU\n",
      "Fetched transcript for video_id vbE5PSu-p0s\n",
      "Fetched transcript for video_id BPRmvlc7ysk\n",
      "Fetched transcript for video_id m69_zJTfmbs\n",
      "Fetched transcript for video_id lOQqGKt52X8\n",
      "Fetched transcript for video_id GLLKeXbSKJ0\n",
      "Fetched transcript for video_id SHJDgWWGZo4\n",
      "Fetched transcript for video_id CgU8ZNEUr0Y\n",
      "Fetched transcript for video_id DME1vicSb1M\n",
      "Fetched transcript for video_id Nss9MYvuIAo\n",
      "Fetched transcript for video_id FydLdwwnGeI\n",
      "Fetched transcript for video_id WPPV6Jbsb5c\n",
      "Fetched transcript for video_id EhAemz1v7dQ\n",
      "Fetched transcript for video_id LxgMdjyw8uw\n",
      "Fetched transcript for video_id ipVxxxqwBQw\n",
      "Fetched transcript for video_id yiw6_JakZFc\n",
      "Fetched transcript for video_id wbR-5mHI6bo\n",
      "Fetched transcript for video_id dSu5sXmsur4\n",
      "Fetched transcript for video_id F1Hq8eVOMHs\n",
      "Fetched transcript for video_id UuGrBhK2c7U\n",
      "Fetched transcript for video_id 75d_29QWELk\n",
      "Fetched transcript for video_id fa8k8IQ1_X0\n",
      "Fetched transcript for video_id LBudghsdByQ\n",
      "Fetched transcript for video_id LrIRuqr_Ozg\n",
      "Fetched transcript for video_id rcOFV4y5z8c\n",
      "Fetched transcript for video_id mZsaaturR6E\n",
      "Fetched transcript for video_id pP44EPBMb8A\n",
      "Fetched transcript for video_id Jzfpyo-q-RM\n",
      "Fetched transcript for video_id QImCld9YubE\n",
      "Fetched transcript for video_id J0ldO87Pprc\n",
      "Fetched transcript for video_id eNx9tvCrvv8\n",
      "Fetched transcript for video_id OWXoRSIxyIU\n",
      "Fetched transcript for video_id XeSu9fBJ2sI\n",
      "Fetched transcript for video_id lGJEihgN4OU\n",
      "Fetched transcript for video_id 2_OEsf-1qgY\n",
      "Fetched transcript for video_id 6YOz9Pxnzho\n",
      "Fetched transcript for video_id Grv1RJkdyqI\n",
      "Fetched transcript for video_id vjDYfvPW4mA\n",
      "Fetched transcript for video_id Yl_K2Ata6XY\n",
      "Fetched transcript for video_id GEmuEWjHr5c\n",
      "Fetched transcript for video_id Ux33-5k8cjg\n",
      "Fetched transcript for video_id LgrXd0NM2y8\n",
      "Fetched transcript for video_id czjisEGe5Cw\n",
      "Fetched transcript for video_id hbXDLKFkjm0\n",
      "Fetched transcript for video_id 5RLQ9WMP2Es\n",
      "Fetched transcript for video_id bHIhgxav9LY\n",
      "Fetched transcript for video_id pHRu0VV-Dbw\n",
      "Fetched transcript for video_id G9t__9Tmwv4\n",
      "Fetched transcript for video_id DMXWC5KtoFg\n",
      "Fetched transcript for video_id VyfTyfEjv9s\n",
      "Fetched transcript for video_id Vl6VhCAeEfQ\n",
      "Fetched transcript for video_id tRA2SfSk2Tc\n",
      "Fetched transcript for video_id MHZMQLDr-OA\n",
      "Fetched transcript for video_id yy3VK6OYBbU\n",
      "Fetched transcript for video_id 6tesHVSZJOg\n",
      "Fetched transcript for video_id p4pWafuvdrY\n",
      "Fetched transcript for video_id 25LW_PG2ZuI\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# traverse each item in json\n",
    "for item in data:\n",
    "    video_id = item.get('video_id')\n",
    "    if not video_id:\n",
    "        print(\"Skipping item with no video_id\")\n",
    "        continue\n",
    "\n",
    "    if 'content' in item and item['content']:\n",
    "        print(f\"Skipping video_id {video_id} as content already exists\")\n",
    "        continue\n",
    "    # fetch transcript using youtube-transcript-api\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi().fetch(video_id)\n",
    "        t_text = \"\"\n",
    "        for entry in transcript:\n",
    "            t_text += entry.text + \" \"\n",
    "\n",
    "        # add t_text to data.content\n",
    "        item['content'] = t_text.strip()\n",
    "        # save the updated item back to json file\n",
    "        with open('youtube-scrape.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        time.sleep(10)\n",
    "        print(f\"Fetched transcript for video_id {video_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching transcript for video_id {video_id}: {e}\")\n",
    "        time.sleep(5)\n",
    "        continue    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
